{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### --- IMPORTANT --- ###\n",
    "# scikit-learn preprocess:\n",
    "# http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing\n",
    "\n",
    "# After finishing the book once, \n",
    "# during review of the book, \n",
    "# read the above page and make additions below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 7.1 Need for Data Pre-processing\n",
    "\n",
    "# - You almost always need to pre-process your data. It is a required step. \n",
    "\n",
    "# - A difficulty is that different algorithms make different assumptions about your data \n",
    "# and may require different transforms. \n",
    "\n",
    "### --- VERY IMPORTANT TO REMEMBER -- ###\n",
    "# - Generally, it is recommended to create many different views and transforms of data, \n",
    "# then exercise a handful of algorithms on each view of dataset. \n",
    "\n",
    "# - This will help to flush out which data transforms might be better at exposing the structure of \n",
    "# the problem in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from numpy import set_printoptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set_printoptions is not required as it does enables the decimal points to the precision defined.\n",
    "# However, does not suppress scientific notation.\n",
    "# We can use numpy savetxt as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_data(_data):\n",
    "    return numpy.savetxt(sys.stdout, _data, '%5.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_uri = 'https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_col_names = ['preg','plas','pres','skin','test','mass','pedi','age','class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_dataframe = read_csv(_uri, names=_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_array = _dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.000 148.000 72.000 35.000 0.000 33.600 0.627 50.000 1.000\n",
      "1.000 85.000 66.000 29.000 0.000 26.600 0.351 31.000 0.000\n",
      "8.000 183.000 64.000 0.000 0.000 23.300 0.672 32.000 1.000\n",
      "1.000 89.000 66.000 23.000 94.000 28.100 0.167 21.000 0.000\n",
      "0.000 137.000 40.000 35.000 168.000 43.100 2.288 33.000 1.000\n"
     ]
    }
   ],
   "source": [
    "print_data(_array[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separate _array into input and output components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_X = _array[:,0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.000 148.000 72.000 35.000 0.000 33.600 0.627 50.000\n",
      "1.000 85.000 66.000 29.000 0.000 26.600 0.351 31.000\n",
      "8.000 183.000 64.000 0.000 0.000 23.300 0.672 32.000\n",
      "1.000 89.000 66.000 23.000 94.000 28.100 0.167 21.000\n",
      "0.000 137.000 40.000 35.000 168.000 43.100 2.288 33.000\n"
     ]
    }
   ],
   "source": [
    "print_data(_X[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_Y = _array[:,8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000\n",
      "0.000\n",
      "1.000\n",
      "0.000\n",
      "1.000\n"
     ]
    }
   ],
   "source": [
    "print_data(_Y[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 7.2 Data Transforms\n",
    "\n",
    "# The scikit-learn library provides two standard idioms for transforming data.\n",
    "# 1. Fit and Multiple Transform.\n",
    "    # - This is the preferred approach.\n",
    "    # - You call the fit() function to prepare the parameters of the transform once on your data.\n",
    "    # - Then later you can use the transform() function on the same data to prepare it for modeling\n",
    "    # and again on the test or validation dataset or new data that you may see in the future.\n",
    "# 2. Combined Fit-And-Transform.\n",
    "    # - The Combined Fit-And-Transform is a convenience that you can use for one off tasks. \n",
    "    # - This might be useful if you are interested in plotting or summarizing the transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 7.3 Rescale Data\n",
    "\n",
    "# - When your data is comprised of attributes with varying scales, many machine learning algorithms \n",
    "# can benefit from rescaling the attributes to all have the same scale. \n",
    "\n",
    "# - Often this is referred to as normalization and attributes are often rescaled into the range \n",
    "# between 0 and 1. \n",
    "\n",
    "# - This is useful for optimization algorithms used in the core of machine learning algorithms \n",
    "# like gradient descent. \n",
    "\n",
    "# - It is also useful for algorithms that weight inputs like regression and neural networks and \n",
    "# algorithms that use distance measures like k-Nearest Neighbors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.000 148.000 72.000 35.000 0.000 33.600 0.627 50.000\n",
      "1.000 85.000 66.000 29.000 0.000 26.600 0.351 31.000\n",
      "8.000 183.000 64.000 0.000 0.000 23.300 0.672 32.000\n",
      "1.000 89.000 66.000 23.000 94.000 28.100 0.167 21.000\n",
      "0.000 137.000 40.000 35.000 168.000 43.100 2.288 33.000\n"
     ]
    }
   ],
   "source": [
    "print_data(_X[:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_X_rescaled = MinMaxScaler(feature_range=(0,1)).fit_transform(_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.353 0.744 0.590 0.354 0.000 0.501 0.234 0.483\n",
      "0.059 0.427 0.541 0.293 0.000 0.396 0.117 0.167\n",
      "0.471 0.920 0.525 0.000 0.000 0.347 0.254 0.183\n",
      "0.059 0.447 0.541 0.232 0.111 0.419 0.038 0.000\n",
      "0.000 0.688 0.328 0.354 0.199 0.642 0.944 0.200\n"
     ]
    }
   ],
   "source": [
    "print_data(_X_rescaled[:5,:]) # rescaled values are between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 7.4 Standardize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# - Standardization is a useful technique to transform attributes with a Gaussian distribution \n",
    "# and differing means and standard deviations to a standard Gaussian distribution with a mean \n",
    "# of 0 and a standard deviation of 1. \n",
    "\n",
    "# - It is most suitable for techniques that assume a Gaussian distribution in the input variables \n",
    "# and work better with rescaled data, such as linear regression, logistic regression and linear \n",
    "# discriminate analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.000 148.000 72.000 35.000 0.000 33.600 0.627 50.000\n",
      "1.000 85.000 66.000 29.000 0.000 26.600 0.351 31.000\n",
      "8.000 183.000 64.000 0.000 0.000 23.300 0.672 32.000\n",
      "1.000 89.000 66.000 23.000 94.000 28.100 0.167 21.000\n",
      "0.000 137.000 40.000 35.000 168.000 43.100 2.288 33.000\n"
     ]
    }
   ],
   "source": [
    "print_data(_X[:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_X_rescaled = StandardScaler().fit_transform(_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.640 0.848 0.150 0.907 -0.693 0.204 0.468 1.426\n",
      "-0.845 -1.123 -0.161 0.531 -0.693 -0.684 -0.365 -0.191\n",
      "1.234 1.944 -0.264 -1.288 -0.693 -1.103 0.604 -0.106\n",
      "-0.845 -0.998 -0.161 0.155 0.123 -0.494 -0.921 -1.042\n",
      "-1.142 0.504 -1.505 0.907 0.766 1.410 5.485 -0.020\n"
     ]
    }
   ],
   "source": [
    "print_data(_X_rescaled[:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 7.5 Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# - Normalizing in scikit-learn refers to rescaling each observation (row) to have a length of 1 \n",
    "# (called a unit norm or a vector with the length of 1 in linear algebra). \n",
    "\n",
    "# - This pre-processing method can be useful for sparse datasets (lots of zeros) with attributes \n",
    "# of varying scales when using algorithms that weight input values such as neural networks and \n",
    "# algorithms that use distance measures such as k-Nearest Neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.000 148.000 72.000 35.000 0.000 33.600 0.627 50.000\n",
      "1.000 85.000 66.000 29.000 0.000 26.600 0.351 31.000\n",
      "8.000 183.000 64.000 0.000 0.000 23.300 0.672 32.000\n",
      "1.000 89.000 66.000 23.000 94.000 28.100 0.167 21.000\n",
      "0.000 137.000 40.000 35.000 168.000 43.100 2.288 33.000\n"
     ]
    }
   ],
   "source": [
    "print_data(_X[:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_X_normalized = Normalizer().fit_transform(_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.034 0.828 0.403 0.196 0.000 0.188 0.004 0.280\n",
      "0.008 0.716 0.556 0.244 0.000 0.224 0.003 0.261\n",
      "0.040 0.924 0.323 0.000 0.000 0.118 0.003 0.162\n",
      "0.007 0.588 0.436 0.152 0.622 0.186 0.001 0.139\n",
      "0.000 0.596 0.174 0.152 0.731 0.188 0.010 0.144\n"
     ]
    }
   ],
   "source": [
    "print_data(_X_normalized[:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for explanation of unit-norm or unit-vector see:\n",
    "# http://www.algebralab.org/lessons/lesson.aspx?file=Trigonometry_TrigVectorUnits.xml\n",
    "\n",
    "# To calculate unit vector of a row:\n",
    "# - square each column value\n",
    "# - add the squared column values\n",
    "# - take square root of the sum\n",
    "# - it should come out to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 7.6 Binarize Data (make binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# - You can transform your data using a binary threshold. \n",
    "# All values above the threshold are marked 1 and all equal to or below are marked as 0. \n",
    "\n",
    "# - It can be useful when you have probabilities that you want to make crisp values. \n",
    "\n",
    "# - It is also useful when feature engineering and you want to add new features that indicate something meaningful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.000 148.000 72.000 35.000 0.000 33.600 0.627 50.000\n",
      "1.000 85.000 66.000 29.000 0.000 26.600 0.351 31.000\n",
      "8.000 183.000 64.000 0.000 0.000 23.300 0.672 32.000\n",
      "1.000 89.000 66.000 23.000 94.000 28.100 0.167 21.000\n",
      "0.000 137.000 40.000 35.000 168.000 43.100 2.288 33.000\n"
     ]
    }
   ],
   "source": [
    "print_data(_X[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_X_binarized = Binarizer(threshold=0.0).fit_transform(_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000 1.000 1.000 1.000 0.000 1.000 1.000 1.000\n",
      "1.000 1.000 1.000 1.000 0.000 1.000 1.000 1.000\n",
      "1.000 1.000 1.000 0.000 0.000 1.000 1.000 1.000\n",
      "1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      "0.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n"
     ]
    }
   ],
   "source": [
    "print_data(_X_binarized[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_X_binarized = Binarizer(threshold=0.5).fit_transform(_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000 1.000 1.000 1.000 0.000 1.000 1.000 1.000\n",
      "1.000 1.000 1.000 1.000 0.000 1.000 0.000 1.000\n",
      "1.000 1.000 1.000 0.000 0.000 1.000 1.000 1.000\n",
      "1.000 1.000 1.000 1.000 1.000 1.000 0.000 1.000\n",
      "0.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n"
     ]
    }
   ],
   "source": [
    "print_data(_X_binarized[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
