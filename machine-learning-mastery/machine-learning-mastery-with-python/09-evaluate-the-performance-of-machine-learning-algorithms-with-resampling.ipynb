{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# - You need to know how well your algorithms perform on unseen data. \n",
    "\n",
    "# - The best way to evaluate the performance of an algorithm would be to make predictions for new data \n",
    "# to which you already know the answers. \n",
    "\n",
    "# The second best way is to use clever techniques from statistics called resampling methods that allow \n",
    "# you to make accurate estimates for how well your algorithm will perform on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 9.1 Evaluate Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# - In order to avoid over-fitting, we can't prepare machine learning algorithms on a training dataset and \n",
    "# use predictions from the same dataset to evaluate performance.\n",
    "\n",
    "# - We must evaluate the machine learning algorithms on data that has not been used to train the algorithms.\n",
    "\n",
    "# - The evaluation is an estimate that we can use to talk about how well we think the algorithm may actually \n",
    "# do in practice. \n",
    "\n",
    "# - It is not a guarantee of performance. \n",
    "\n",
    "# - Once we estimate the performance of our algorithm, we can then re-train the final algorithm on the entire \n",
    "# training dataset and get it ready for operational use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_data(_data):\n",
    "    return numpy.savetxt(sys.stdout, _data[:5,:], '%5.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_uri = 'https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_col_names = ['preg','plas','pres','skin','test','mass','pedi','age','class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_dataframe = read_csv(_uri, names=_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_array = _dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.000 148.000 72.000 35.000 0.000 33.600 0.627 50.000 1.000\n",
      "1.000 85.000 66.000 29.000 0.000 26.600 0.351 31.000 0.000\n",
      "8.000 183.000 64.000 0.000 0.000 23.300 0.672 32.000 1.000\n",
      "1.000 89.000 66.000 23.000 94.000 28.100 0.167 21.000 0.000\n",
      "0.000 137.000 40.000 35.000 168.000 43.100 2.288 33.000 1.000\n"
     ]
    }
   ],
   "source": [
    "print_data(_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_X = _array[:,0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.000 148.000 72.000 35.000 0.000 33.600 0.627 50.000\n",
      "1.000 85.000 66.000 29.000 0.000 26.600 0.351 31.000\n",
      "8.000 183.000 64.000 0.000 0.000 23.300 0.672 32.000\n",
      "1.000 89.000 66.000 23.000 94.000 28.100 0.167 21.000\n",
      "0.000 137.000 40.000 35.000 168.000 43.100 2.288 33.000\n"
     ]
    }
   ],
   "source": [
    "print_data(_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_Y = _array[:,8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000\n",
      "0.000\n",
      "1.000\n",
      "0.000\n",
      "1.000\n"
     ]
    }
   ],
   "source": [
    "print_data(_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_Y = numpy.ravel(_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  1.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(_Y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 9.2 Split into Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# - The size of the split can depend on the size and specifics of your dataset, although it is common\n",
    "# to use 67% of the data for training and the remaining 33% for testing.\n",
    "\n",
    "# - This algorithm evaluation technique is very fast. \n",
    "\n",
    "# - It is ideal for large datasets (millions of records) where there is strong evidence that both splits \n",
    "# of the data are representative of the underlying problem. Because of the speed, it is useful to use this \n",
    "# approach when the algorithm you are investigating is slow to train. \n",
    "\n",
    "# - A downside of this technique is that it can have a high variance. This means that differences in the \n",
    "# training and test dataset can result in meaningful differences in the estimate of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_test_size = 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_X_train, _X_test, _Y_train, _Y_test = train_test_split(_X, _Y, test_size=_test_size, random_state=_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_model.fit(_X_train, _Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_score = _model.score(_X_test, _Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75590551181102361"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 75.59%\n"
     ]
    }
   ],
   "source": [
    "print('accuracy: {:.2%}'.format(_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 9.3 K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# - Cross-validation is an approach that you can use to estimate the performance of a machine learning \n",
    "# algorithm with less variance than a single train-test set split. \n",
    "\n",
    "# - It works by splitting the dataset into k-parts (e.g. k = 5 or k = 10). Each split of the data is called \n",
    "# a fold. The algorithm is trained on k âˆ’ 1 folds with one held back and tested on the held back fold. \n",
    "# This is repeated so that each fold of the dataset is given a chance to be the held back test set. \n",
    "# After running cross-validation you end up with k different performance scores that you can summarize \n",
    "# using a mean and a standard deviation.\n",
    "\n",
    "# - The result is a more reliable estimate of the performance of the algorithm on new data. \n",
    "# It is more accurate because the algorithm is trained and evaluated multiple times on different data.\n",
    "\n",
    "# - For modest sized datasets in the thousands or tens of thousands of records, k values of 3, 5 and 10 are common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_num_folds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_kfold = KFold(n_splits=_num_folds, random_state=_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_score = cross_val_score(_model, _X, _Y, cv=_kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 76.95%, 4.84%\n"
     ]
    }
   ],
   "source": [
    "print('accuracy: {:.2%}, {:.2%}'.format(_score.mean(), _score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 9.4 Leave One Out Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# - You can configure cross-validation so that the size of the fold is 1 (k is set to the number \n",
    "# of observations in your dataset). \n",
    "\n",
    "# - This variation of cross-validation is called leave-one-out cross- validation. \n",
    "\n",
    "# - The result is a large number of performance measures that can be summarized in an effort to \n",
    "# give a more reasonable estimate of the accuracy of your model on unseen data. \n",
    "\n",
    "# - A downside is that it can be a computationally more expensive procedure than k-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_loo = LeaveOneOut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_score = cross_val_score(_model, _X, _Y, cv=_loo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 76.82%, 42.20%\n"
     ]
    }
   ],
   "source": [
    "print('accuracy: {:.2%}, {:.2%}'.format(_score.mean(), _score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# - You can see in the standard deviation that the score has more variance than the k-fold \n",
    "# cross-validation results described above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 9.5 Repeated Random Test-Train Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# - Another variation on k-fold cross-validation is to create a random split of the data like \n",
    "# the train/test split described above, but repeat the process of splitting and evaluation of \n",
    "# the algorithm multiple times, like cross-validation. \n",
    "\n",
    "# - This has the speed of using a train/test split and the reduction in variance in the estimated \n",
    "# performance of k-fold cross-validation. \n",
    "\n",
    "# - You can also repeat the process many more times as needed to improve the accuracy. \n",
    "\n",
    "# - A down side is that repetitions may include much of the same data in the train or the test \n",
    "# split from run to run, introducing redundancy into the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_n_splits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_test_size = 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_kfold = ShuffleSplit(n_splits=_n_splits, test_size=_test_size, random_state=_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_score = cross_val_score(_model, _X, _Y, cv=_kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 76.50%, 1.70%\n"
     ]
    }
   ],
   "source": [
    "print('accuracy: {:.2%}, {:.2%}'.format(_score.mean(), _score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 9.6 What Techniques to Use When"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# - Generally k-fold cross-validation is the gold standard for evaluating the performance of a \n",
    "# machine learning algorithm on unseen data with k set to 3, 5, or 10.\n",
    "\n",
    "# - Using a train/test split is good for speed when using a slow algorithm and produces performance \n",
    "# estimates with lower bias when using large datasets.\n",
    "  \n",
    "# - Techniques like leave-one-out cross-validation and repeated random splits can be useful intermediates \n",
    "# when trying to balance variance in the estimated performance, model training speed and dataset size.\n",
    "\n",
    "# - The best advice is to experiment and find a technique for your problem that is fast and produces \n",
    "# reasonable estimates of performance that you can use to make decisions. \n",
    "\n",
    "# - If in doubt, use 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
