{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notes: [How To Work with Language Data in Python 3 using the Natural Language Toolkit (NLTK)](https://www.digitalocean.com/community/tutorials/how-to-work-with-language-data-in-python-3-using-the-natural-language-toolkit-nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nltk version: 3.2.2\n"
     ]
    }
   ],
   "source": [
    "print('nltk version: {}'.format(nltk.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nltk twitter corpus contains 20K tweets from twitter streaming api.\n",
    "# Tweets are stored in JSON format.\n",
    "from nltk.corpus import twitter_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative_tweets.json', 'positive_tweets.json', 'tweets.20150430-223406.json']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JSON files in the corpus\n",
    "twitter_samples.fileids()\n",
    "\n",
    "# if get error: Resource 'corpora/twitter_samples.zip/twitter_samples/' not found.\n",
    "# use on command line: $ python -m nltk.downloader twitter_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)', '@Lamb2ja Hey James! How odd :/ Please call our Contact Centre on 02392441234 and we will be able to assist you :) Many thanks!', '@DespiteOfficial we had a listen last night :) As You Bleed is an amazing track. When are you in Scotland?!', '@97sides CONGRATS :)', 'yeaaaah yippppy!!!  my accnt verified rqst has succeed got a blue tick mark on my fb profile :) in 15 days', '@BhaktisBanter @PallaviRuhail This one is irresistible :)\\n#FlipkartFashionFriday http://t.co/EbZ0L2VENM', \"We don't like to keep our lovely customers waiting for long! We hope you enjoy! Happy Friday! - LWWF :) https://t.co/smyYriipxI\", '@Impatientraider On second thought, there’s just not enough time for a DD :) But new shorts entering system. Sheep must be buying.', 'Jgh , but we have to go to Bayan :D bye', 'As an act of mischievousness, am calling the ETL layer of our in-house warehousing app Katamari.\\n\\nWell… as the name implies :p.']\n"
     ]
    }
   ],
   "source": [
    "# objective: to count the number of nouns [helps determine topics being discussed] \n",
    "# and adjectives [helps determine what type of language is being used, i.e. opinions\n",
    "# tend to include more adjectives than facts] that appear in the positive subset of \n",
    "# the twitter corpus\n",
    "pos_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "print(pos_tweets[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['#FollowFriday', '@France_Inte', '@PKuchly57', '@Milipol_Paris', 'for', 'being', 'top', 'engaged', 'members', 'in', 'my', 'community', 'this', 'week', ':)'], ['@Lamb2ja', 'Hey', 'James', '!', 'How', 'odd', ':/', 'Please', 'call', 'our', 'Contact', 'Centre', 'on', '02392441234', 'and', 'we', 'will', 'be', 'able', 'to', 'assist', 'you', ':)', 'Many', 'thanks', '!'], ['@DespiteOfficial', 'we', 'had', 'a', 'listen', 'last', 'night', ':)', 'As', 'You', 'Bleed', 'is', 'an', 'amazing', 'track', '.', 'When', 'are', 'you', 'in', 'Scotland', '?', '!'], ['@97sides', 'CONGRATS', ':)'], ['yeaaaah', 'yippppy', '!', '!', '!', 'my', 'accnt', 'verified', 'rqst', 'has', 'succeed', 'got', 'a', 'blue', 'tick', 'mark', 'on', 'my', 'fb', 'profile', ':)', 'in', '15', 'days'], ['@BhaktisBanter', '@PallaviRuhail', 'This', 'one', 'is', 'irresistible', ':)', '#FlipkartFashionFriday', 'http://t.co/EbZ0L2VENM'], ['We', \"don't\", 'like', 'to', 'keep', 'our', 'lovely', 'customers', 'waiting', 'for', 'long', '!', 'We', 'hope', 'you', 'enjoy', '!', 'Happy', 'Friday', '!', '-', 'LWWF', ':)', 'https://t.co/smyYriipxI'], ['@Impatientraider', 'On', 'second', 'thought', ',', 'there', '’', 's', 'just', 'not', 'enough', 'time', 'for', 'a', 'DD', ':)', 'But', 'new', 'shorts', 'entering', 'system', '.', 'Sheep', 'must', 'be', 'buying', '.'], ['Jgh', ',', 'but', 'we', 'have', 'to', 'go', 'to', 'Bayan', ':D', 'bye'], ['As', 'an', 'act', 'of', 'mischievousness', ',', 'am', 'calling', 'the', 'ETL', 'layer', 'of', 'our', 'in-house', 'warehousing', 'app', 'Katamari', '.', 'Well', '…', 'as', 'the', 'name', 'implies', ':p', '.']]\n"
     ]
    }
   ],
   "source": [
    "# Tokenization: breaking up a sequence of strings into pieces such as words, keywords, \n",
    "# phrases, symbols and other elements, which are called tokens.\n",
    "pos_tweets_tokens = twitter_samples.tokenized('positive_tweets.json')\n",
    "print(pos_tweets_tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# POS (part-of-speech) tagging is the process of labelling a word in a text as \n",
    "# corresponding to a particular POS tag: nouns, verbs, adjectives, adverbs, etc.\n",
    "# NLTK's averaged_perceptron_tagger uses the perceptron algorithm to predict which \n",
    "# POS tag is most likely given the word\n",
    "from nltk.tag import pos_tag_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('#FollowFriday', 'JJ'), ('@France_Inte', 'NNP'), ('@PKuchly57', 'NNP'), ('@Milipol_Paris', 'NNP'), ('for', 'IN'), ('being', 'VBG'), ('top', 'JJ'), ('engaged', 'VBN'), ('members', 'NNS'), ('in', 'IN'), ('my', 'PRP$'), ('community', 'NN'), ('this', 'DT'), ('week', 'NN'), (':)', 'NN')], [('@Lamb2ja', 'NN'), ('Hey', 'NNP'), ('James', 'NNP'), ('!', '.'), ('How', 'NNP'), ('odd', 'JJ'), (':/', 'NNP'), ('Please', 'NNP'), ('call', 'VB'), ('our', 'PRP$'), ('Contact', 'NNP'), ('Centre', 'NNP'), ('on', 'IN'), ('02392441234', 'CD'), ('and', 'CC'), ('we', 'PRP'), ('will', 'MD'), ('be', 'VB'), ('able', 'JJ'), ('to', 'TO'), ('assist', 'VB'), ('you', 'PRP'), (':)', 'VBP'), ('Many', 'JJ'), ('thanks', 'NNS'), ('!', '.')], [('@DespiteOfficial', 'JJ'), ('we', 'PRP'), ('had', 'VBD'), ('a', 'DT'), ('listen', 'VBN'), ('last', 'JJ'), ('night', 'NN'), (':)', 'NN'), ('As', 'IN'), ('You', 'PRP'), ('Bleed', 'VBP'), ('is', 'VBZ'), ('an', 'DT'), ('amazing', 'JJ'), ('track', 'NN'), ('.', '.'), ('When', 'WRB'), ('are', 'VBP'), ('you', 'PRP'), ('in', 'IN'), ('Scotland', 'NNP'), ('?', '.'), ('!', '.')], [('@97sides', 'NNS'), ('CONGRATS', 'NNP'), (':)', 'VBP')], [('yeaaaah', 'NN'), ('yippppy', 'JJ'), ('!', '.'), ('!', '.'), ('!', '.'), ('my', 'PRP$'), ('accnt', 'JJ'), ('verified', 'VBN'), ('rqst', 'NN'), ('has', 'VBZ'), ('succeed', 'VB'), ('got', 'VBD'), ('a', 'DT'), ('blue', 'JJ'), ('tick', 'NN'), ('mark', 'NN'), ('on', 'IN'), ('my', 'PRP$'), ('fb', 'NN'), ('profile', 'NN'), (':)', 'NN'), ('in', 'IN'), ('15', 'CD'), ('days', 'NNS')], [('@BhaktisBanter', 'RB'), ('@PallaviRuhail', 'NN'), ('This', 'DT'), ('one', 'CD'), ('is', 'VBZ'), ('irresistible', 'JJ'), (':)', 'JJ'), ('#FlipkartFashionFriday', 'NN'), ('http://t.co/EbZ0L2VENM', 'NN')], [('We', 'PRP'), (\"don't\", 'VBP'), ('like', 'IN'), ('to', 'TO'), ('keep', 'VB'), ('our', 'PRP$'), ('lovely', 'JJ'), ('customers', 'NNS'), ('waiting', 'VBG'), ('for', 'IN'), ('long', 'RB'), ('!', '.'), ('We', 'PRP'), ('hope', 'VBP'), ('you', 'PRP'), ('enjoy', 'VBP'), ('!', '.'), ('Happy', 'JJ'), ('Friday', 'NNP'), ('!', '.'), ('-', ':'), ('LWWF', 'NNP'), (':)', 'NNP'), ('https://t.co/smyYriipxI', 'NN')], [('@Impatientraider', 'NN'), ('On', 'IN'), ('second', 'JJ'), ('thought', 'NN'), (',', ','), ('there', 'EX'), ('’', 'NNP'), ('s', 'NN'), ('just', 'RB'), ('not', 'RB'), ('enough', 'JJ'), ('time', 'NN'), ('for', 'IN'), ('a', 'DT'), ('DD', 'NNP'), (':)', 'NNP'), ('But', 'CC'), ('new', 'JJ'), ('shorts', 'NNS'), ('entering', 'VBG'), ('system', 'NN'), ('.', '.'), ('Sheep', 'VB'), ('must', 'MD'), ('be', 'VB'), ('buying', 'VBG'), ('.', '.')], [('Jgh', 'NNP'), (',', ','), ('but', 'CC'), ('we', 'PRP'), ('have', 'VBP'), ('to', 'TO'), ('go', 'VB'), ('to', 'TO'), ('Bayan', 'NNP'), (':D', 'NNP'), ('bye', 'NN')], [('As', 'IN'), ('an', 'DT'), ('act', 'NN'), ('of', 'IN'), ('mischievousness', 'NN'), (',', ','), ('am', 'VBP'), ('calling', 'VBG'), ('the', 'DT'), ('ETL', 'NNP'), ('layer', 'NN'), ('of', 'IN'), ('our', 'PRP$'), ('in-house', 'NN'), ('warehousing', 'VBG'), ('app', 'JJ'), ('Katamari', 'NNP'), ('.', '.'), ('Well', 'NNP'), ('…', 'RB'), ('as', 'IN'), ('the', 'DT'), ('name', 'NN'), ('implies', 'VBZ'), (':p', 'NNP'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "pos_tweets_tokens_tagged = pos_tag_sents(pos_tweets_tokens)\n",
    "print(pos_tweets_tokens_tagged[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adjectives: 6094\n",
      "singular nouns: 13180\n",
      "plural nouns: 2429\n"
     ]
    }
   ],
   "source": [
    "# in nltk, [JJ]=adjectives, [NN]=singular nouns, [NNS]=plural nouns\n",
    "count_JJ = 0\n",
    "count_NN = 0\n",
    "count_NNS = 0\n",
    "\n",
    "for tweet in pos_tweets_tokens_tagged:\n",
    "    for pair in tweet:\n",
    "        tag = pair[1]\n",
    "        if tag == 'JJ':\n",
    "            count_JJ += 1\n",
    "        elif tag == 'NN':\n",
    "            count_NN += 1\n",
    "        elif tag == 'NNS':\n",
    "            count_NNS += 1\n",
    "print('adjectives: {}'.format(count_JJ))\n",
    "print('singular nouns: {}'.format(count_NN))\n",
    "print('plural nouns: {}'.format(count_NNS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# todo: extend this script to count positive adjectives (great, awesome, happy, etc.) \n",
    "# versus negative adjectives (boring, lame, sad, etc.), which could be used to analyze \n",
    "# the sentiment of tweets or reviews about a product or movie, for example. This script \n",
    "# provides data that can in turn inform decisions related to that product or movie."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
