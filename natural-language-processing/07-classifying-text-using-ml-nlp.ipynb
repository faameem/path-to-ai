{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_all_doxy_donkey_posts(_url,_links):\n",
    "    _response = requests.get(_url)\n",
    "    _response.raise_for_status()\n",
    "    _soup = BeautifulSoup(_response.content, 'lxml')\n",
    "    for _a in _soup.findAll('a'):\n",
    "        try:\n",
    "            _url = _a['href']\n",
    "            _title = _a['title']\n",
    "            if _title == \"Older Posts\":\n",
    "                _links.append(_url)\n",
    "                get_all_doxy_donkey_posts(_url,_links)\n",
    "        except:\n",
    "            _title = \"\"\n",
    "    return\n",
    "\n",
    "_blogUrl = \"http://doxydonkey.blogspot.in\"\n",
    "_links = []\n",
    "get_all_doxy_donkey_posts(_blogUrl,_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://doxydonkey.blogspot.in/search?updated-max=2017-04-09T18:57:00-07:00&max-results=7',\n",
       " 'http://doxydonkey.blogspot.in/search?updated-max=2017-03-29T19:55:00-07:00&max-results=7&start=7&by-date=false',\n",
       " 'http://doxydonkey.blogspot.in/search?updated-max=2017-03-19T20:14:00-07:00&max-results=7&start=14&by-date=false',\n",
       " 'http://doxydonkey.blogspot.in/search?updated-max=2017-03-01T19:14:00-08:00&max-results=7&start=21&by-date=false',\n",
       " 'http://doxydonkey.blogspot.in/search?updated-max=2017-02-20T18:07:00-08:00&max-results=7&start=28&by-date=false',\n",
       " 'http://doxydonkey.blogspot.in/search?updated-max=2017-02-09T18:22:00-08:00&max-results=7&start=35&by-date=false',\n",
       " 'http://doxydonkey.blogspot.in/search?updated-max=2017-01-31T17:57:00-08:00&max-results=7&start=42&by-date=false',\n",
       " 'http://doxydonkey.blogspot.in/search?updated-max=2017-01-19T17:44:00-08:00&max-results=7&start=49&by-date=false',\n",
       " 'http://doxydonkey.blogspot.in/search?updated-max=2017-01-10T18:06:00-08:00&max-results=7&start=56&by-date=false',\n",
       " 'http://doxydonkey.blogspot.in/search?updated-max=2017-01-01T18:20:00-08:00&max-results=7&start=63&by-date=false',\n",
       " 'http://doxydonkey.blogspot.in/search?updated-max=2016-12-21T18:55:00-08:00&max-results=7&start=70&by-date=false',\n",
       " 'http://doxydonkey.blogspot.in/search?updated-max=2016-12-12T19:04:00-08:00&max-results=7&start=77&by-date=false',\n",
       " 'http://doxydonkey.blogspot.in/search?updated-max=2016-09-26T00:28:00-07:00&max-results=7&start=84&by-date=false',\n",
       " 'http://doxydonkey.blogspot.in/search?updated-max=2016-09-08T03:41:00-07:00&max-results=7&start=91&by-date=false',\n",
       " 'http://doxydonkey.blogspot.in/search?updated-max=2016-08-25T21:48:00-07:00&max-results=7&start=98&by-date=false',\n",
       " 'http://doxydonkey.blogspot.in/search?updated-max=2016-08-16T19:49:00-07:00&max-results=7&start=105&by-date=false',\n",
       " 'http://doxydonkey.blogspot.in/search?updated-max=2016-08-04T20:26:00-07:00&max-results=7&start=112&by-date=false',\n",
       " 'http://doxydonkey.blogspot.in/search?updated-max=2016-07-25T19:21:00-07:00&max-results=7&start=119&by-date=false',\n",
       " 'http://doxydonkey.blogspot.in/search?updated-max=2016-07-14T19:28:00-07:00&max-results=7&start=126&by-date=false']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_links[:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_doxy_donkey_post_text(_url):\n",
    "    _response = requests.get(_url)\n",
    "    _response.raise_for_status()\n",
    "    _soup = BeautifulSoup(_response.content,'lxml')\n",
    "    _divs = _soup.findAll(\"div\", {\"class\":'post-body'})\n",
    "    \n",
    "    _posts =[]\n",
    "    for _div in _divs:\n",
    "        _posts += map(lambda _p:_p.text.encode('ascii', errors='replace').decode().replace(\"?\",\" \"), _div.findAll(\"li\"))\n",
    "    return _posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_doxy_donkey_post_text = []\n",
    "for _link in _links:\n",
    "    _doxy_donkey_post_text += get_doxy_donkey_post_text(_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2720"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_doxy_donkey_post_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lyft Gets $500 Million in New Funding as Its Rival Uber Wobbles: For years, Lyft has trailed its larger rival Uber in the battle to conquer the ride-hailing market. More recently, Lyft has gotten a boost. The smaller ride-hailing company has secured up to $500 million in a new round of funding that values Lyft at $6.9 billion before the addition of new capital, according to two people briefed on the discussions, who asked to remain anonymous because the details were confidential. The privately held company may raise an additional $100 million, these people said. The financing gave Lyft a $2.4 billion increase in value since the company last raised money in 2016. It was not immediately clear which investors were participating in the new financing. Lyft s previous investors included the venture capital firm Andreessen Horowitz and Chinese e-commerce company Alibaba. Lyft is being bolstered by the woes at Uber, which has been dealing with scandals involving the company s workplace culture and aggressive leadership team. A grass-roots movement to boycott Uber has sprung up around the country, with the hashtag #deleteuber spreading quickly across Twitter related to the company s shortcomings.',\n",
       " 'Samsung Withstands Scandals to Report Higher Profit, Revenue: Samsung Electronics Co. posted its best operating profit in almost four years on robust sales of memory chips and displays, showing that the core businesses remain stable even as its mobile unit recovers from a costly recall and the trial of the group s de facto chief. Operating income rose 48 percent to 9.9 trillion won ($8.74 billion) in the three months ended March, the Suwon, South Korea-based company said in preliminary resultsreleased Friday. That compares with the 9.18 trillion-won average of analysts  estimatescompiled by Bloomberg. Rising demand for memory chips and organic light-emitting diode screens helped to fuel a rise in sales to 50 trillion won in the quarter, compared with the 49.5 trillion won analysts expected. The results also underscore how the electronics conglomerate is recovering from last year s Note 7 crisis, when some smartphones burst into flames and forced Samsung to pull it from shelves. That was followed by the arrest of de facto chief Jay Y. Lee in February in connection with an influence-peddling scandal. Samsung s shares fell less than 1 percent in Seoul. They have climbed about 16 percent this year and are trading near record highs.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_doxy_donkey_post_text[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x3 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://www.scipy-lectures.org/advanced/scipy_sparse/csr_matrix.html\n",
    "# Compressed Sparse Row Format\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "row = np.array([0, 0, 1, 2, 2, 2])\n",
    "col = np.array([0, 2, 2, 0, 1, 2])\n",
    "data = np.array([1, 2, 3, 4, 5, 6])\n",
    "mtx = sparse.csr_matrix((data, (row, col)), shape=(3, 3))\n",
    "mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mtx type:\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "mtx:\n",
      "  (0, 0)\t1\n",
      "  (0, 2)\t2\n",
      "  (1, 2)\t3\n",
      "  (2, 0)\t4\n",
      "  (2, 1)\t5\n",
      "  (2, 2)\t6\n",
      "mtx data:\n",
      "[1 2 3 4 5 6]\n",
      "mtx indices:\n",
      "[0 2 2 0 1 2]\n",
      "mtx indptr:\n",
      "[0 2 3 6]\n",
      "mtx[0]:\n",
      "  (0, 0)\t1\n",
      "  (0, 2)\t2\n",
      "mtx[1]:\n",
      "  (0, 2)\t3\n",
      "mtx[2]:\n",
      "  (0, 0)\t4\n",
      "  (0, 1)\t5\n",
      "  (0, 2)\t6\n",
      "mtx.todense():\n",
      "[[1 0 2]\n",
      " [0 0 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "print('mtx type:\\n{}'.format(type(mtx)))\n",
    "print('mtx:\\n{}'.format(mtx))  \n",
    "print('mtx data:\\n{}'.format(mtx.data))\n",
    "print('mtx indices:\\n{}'.format(mtx.indices))\n",
    "print('mtx indptr:\\n{}'.format(mtx.indptr))\n",
    "print('mtx[0]:\\n{}'.format(mtx[0]))\n",
    "print('mtx[1]:\\n{}'.format(mtx[1]))\n",
    "print('mtx[2]:\\n{}'.format(mtx[2]))\n",
    "print('mtx.todense():\\n{}'.format(mtx.todense()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature extraction is very different from Feature selection: \n",
    "# The former consists in transforming arbitrary data, such as text or images, into numerical features usable \n",
    "# for machine learning. The latter is a machine learning technique applied on these features.\n",
    "\n",
    "# Read 4.2.3 Text feature extraction of:\n",
    "# http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.feature_extraction.text.TfidfVectorizer"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2720x13036 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 272341 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = _vectorizer.fit_transform(_doxy_donkey_post_text)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13036"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_feature_names = _vectorizer.get_feature_names()\n",
    "len(X_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abc'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_feature_names[600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x13036 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 40 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[2719]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7097)\t0.569595161783\n",
      "  (0, 5262)\t0.0700602601136\n",
      "  (0, 396)\t0.118132551753\n",
      "  (0, 7467)\t0.0963956010011\n",
      "  (0, 7825)\t0.115382094654\n",
      "  (0, 5143)\t0.113124391152\n",
      "  (0, 9924)\t0.128075641977\n",
      "  (0, 12155)\t0.22252806633\n",
      "  (0, 12967)\t0.0407374611878\n",
      "  (0, 11948)\t0.115162237042\n",
      "  (0, 6722)\t0.0680265301427\n",
      "  (0, 1588)\t0.0799061050617\n",
      "  (0, 2873)\t0.120727332597\n",
      "  (0, 9888)\t0.124227255471\n",
      "  (0, 5516)\t0.132677365117\n",
      "  (0, 7223)\t0.0390658829355\n",
      "  (0, 9418)\t0.0570476676203\n",
      "  (0, 5358)\t0.100486651575\n",
      "  (0, 1854)\t0.0685825333755\n",
      "  (0, 10701)\t0.0703723361386\n",
      "  (0, 10267)\t0.0947831490321\n",
      "  (0, 10001)\t0.0562239519141\n",
      "  (0, 12439)\t0.0871826963202\n",
      "  (0, 1720)\t0.064482905215\n",
      "  (0, 740)\t0.0723795887207\n",
      "  :\t:\n",
      "  (0, 2442)\t0.052573486422\n",
      "  (0, 2698)\t0.0508416155522\n",
      "  (0, 938)\t0.0560905678152\n",
      "  (0, 1827)\t0.115162237042\n",
      "  (0, 12864)\t0.117711818166\n",
      "  (0, 3354)\t0.103697902476\n",
      "  (0, 10157)\t0.115162237042\n",
      "  (0, 6369)\t0.101489354849\n",
      "  (0, 12895)\t0.102556792213\n",
      "  (0, 3237)\t0.0885428765226\n",
      "  (0, 868)\t0.08366702814\n",
      "  (0, 6773)\t0.0885428765226\n",
      "  (0, 11601)\t0.0626974367655\n",
      "  (0, 9989)\t0.102556792213\n",
      "  (0, 7647)\t0.104923614143\n",
      "  (0, 1900)\t0.129176152732\n",
      "  (0, 10947)\t0.124418023983\n",
      "  (0, 3101)\t0.0582139330799\n",
      "  (0, 5589)\t0.104923614143\n",
      "  (0, 3461)\t0.129176152732\n",
      "  (0, 10940)\t0.111005612348\n",
      "  (0, 9239)\t0.0651482740814\n",
      "  (0, 12142)\t0.0550605361339\n",
      "  (0, 9566)\t0.0729219172619\n",
      "  (0, 10487)\t0.124418023983\n"
     ]
    }
   ],
   "source": [
    "print('{}'.format(X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters = 3, init = 'k-means++', max_iter = 100, n_init = 1, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 5149.220\n",
      "Iteration  1, inertia 2601.262\n",
      "Iteration  2, inertia 2593.876\n",
      "Iteration  3, inertia 2591.752\n",
      "Iteration  4, inertia 2590.196\n",
      "Iteration  5, inertia 2589.578\n",
      "Iteration  6, inertia 2589.430\n",
      "Iteration  7, inertia 2589.356\n",
      "Iteration  8, inertia 2589.311\n",
      "Iteration  9, inertia 2589.271\n",
      "Iteration 10, inertia 2589.239\n",
      "Iteration 11, inertia 2589.211\n",
      "Iteration 12, inertia 2589.184\n",
      "Iteration 13, inertia 2589.140\n",
      "Iteration 14, inertia 2589.075\n",
      "Iteration 15, inertia 2589.017\n",
      "Iteration 16, inertia 2588.966\n",
      "Iteration 17, inertia 2588.942\n",
      "Iteration 18, inertia 2588.932\n",
      "Iteration 19, inertia 2588.923\n",
      "Iteration 20, inertia 2588.896\n",
      "Iteration 21, inertia 2588.877\n",
      "Iteration 22, inertia 2588.876\n",
      "Converged at iteration 22: center shift 0.000000e+00 within tolerance 7.409231e-09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "    n_clusters=3, n_init=1, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 2, 1, 2], dtype=int32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2720"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.15370803e-04,   4.75180056e-03,   0.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  1.30648178e-04,   8.40625025e-03,   5.54647198e-05, ...,\n",
       "          0.00000000e+00,   1.68266659e-04,   1.10237007e-04],\n",
       "       [  7.93802821e-04,   8.18578801e-03,   1.46484929e-04, ...,\n",
       "          2.37243213e-04,   0.00000000e+00,   1.00115569e-03]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(km.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2], dtype=int32), array([ 187, 1576,  957]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(km.labels_, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_text = {}\n",
    "for _idx, _cluster in enumerate(km.labels_):\n",
    "    _document = _doxy_donkey_post_text[_idx]\n",
    "    if _cluster not in _text.keys():\n",
    "        _text[_cluster] = _document\n",
    "    else:\n",
    "        _text[_cluster] += _document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "309508\n",
      "2483667\n",
      "1395004\n",
      "Australian regulator sues Apple alleging iPhone 'bricking': Australia's consumer watchdog has sued Apple Inc (AAPL.O) alleging it used a software update to disable iPhones which had cracked screens fixed by third parties. The U.S. technology giant \"bricked\" - or disabled with a software update - hundreds of smartphones and tablet devices, and then refused to unlock them on the grounds that customers had had the devices serviced by non-Apple repairers, the Australian Competition and Consumer Commission said in a court filing. \"Consumer guarantee rights under the Australian Consumer Law exist independently of any manufacturer's warranty and are not extinguished simply because a consumer has goods repaired by a third party,\" ACCC Chairman Rod Sims said in a statement. The regulator said that between September 2014 and February 2016, Apple customers who downloaded software updates then connected their devices to their computers received a message saying the device \"could not be restored an\n"
     ]
    }
   ],
   "source": [
    "print(len(_text))\n",
    "print(len(_text[0]))\n",
    "print(len(_text[1]))\n",
    "print(len(_text[2]))\n",
    "print(_text[0][0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from collections import defaultdict\n",
    "from string import punctuation\n",
    "from heapq import nlargest\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_stopwords = set(stopwords.words('english') + list(punctuation)+[\"million\",\"billion\",\"year\",\"millions\",\"billions\",\"y/y\",\"'s\",\"''\",\"``\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_keywords = {}\n",
    "_counts={}\n",
    "for _cluster in range(3):\n",
    "    _word_sent = word_tokenize(_text[_cluster].lower())\n",
    "    _word_sent=[_word for _word in _word_sent if _word not in _stopwords]\n",
    "    _freq = FreqDist(_word_sent)\n",
    "    _keywords[_cluster] = nlargest(100, _freq, key=_freq.get)\n",
    "    _counts[_cluster]=_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['apple', 'company', 'said', 'iphone', 'new', 'percent', 'sales', 'pay', 'china', 'watch', 'also', 'market', 'app', 'google', 'mobile', 'samsung', 'according', 'quarter', 'last', 'first', 'would', 'apps', 'one', 'service', 'iphones', 'like', 'smartphone', 'devices', 'store', 'revenue', 'could', 'people', 'years', 'technology', 'phones', 'music', 'may', 'u.s.', 'phone', 'payments', 'time', 'use', 'make', 'sold', 'stores', 'world', 'customers', 'companies', 'business', 'data', 'product', 'android', 'smartphones', 'users', 'since', 'services', 'cook', 'device', 'two', 'much', 'india', 'software', 'products', 'analyst', 'buy', 'research', 'inc.', 'many', 'well', 'consumers', 'tv', 'months', 'shares', 'maker', 'still', 'system', 'growth', 'reported', 'even', 'government', 'ipad', 'credit', 'used', 'including', 'profit', '6', 'chinese', 'industry', 'next', 'analysts', 'firm', 'chief', 'less', 'already', 'electronics', 'price', 'payment', 'big', 'executive', 'streaming'], 1: ['company', 'said', 'google', 'facebook', 'new', 'amazon', 'users', 'like', 'also', 'people', 'one', 'companies', 'app', 'service', 'data', 'mobile', 'online', 'twitter', 'would', 'business', 'last', 'percent', 'ads', 'technology', 'could', 'video', 'services', 'time', 'according', 'uber', 'first', 'make', 'customers', 'use', 'products', 'many', 'product', 'search', 'internet', 'india', 'two', 'ad', 'years', 'mr.', 'even', 'get', 'software', 'way', 'social', 'apps', 'may', 'including', 'much', 'buy', 'world', 'microsoft', 'tech', 'sales', 'china', 'platform', 'market', 'big', 'using', 'site', 'revenue', 'says', 'still', 'content', 'u.s.', 'web', 'announced', 'made', 'information', 'news', 'since', 'called', 'month', 'help', 'money', 'user', 'system', 'around', 'advertising', 'industry', 'chief', 'digital', 'media', 'executive', 'number', 'work', 'pay', 'see', 'network', 'free', 'well', 'part', 'another', 'devices', 'take', 'used'], 2: ['company', 'percent', 'said', 'revenue', 'investors', 'shares', 'quarter', 'last', 'new', 'china', 'market', 'alibaba', 'business', 'companies', 'also', 'sales', 'uber', 'growth', 'according', 'share', 'stock', 'would', 'first', 'one', 'online', 'profit', 'round', 'public', 'valuation', 'years', 'like', 'chinese', 'inc.', 'india', 'people', 'capital', 'raised', 'mobile', 'since', 'per', 'firm', 'reported', 'rose', 'analysts', 'deal', 'earnings', 'services', 'investment', 'money', 'private', '1', 'data', 'funding', 'value', 'two', 'u.s.', 'net', 'trading', 'e-commerce', 'time', 'including', 'technology', 'group', 'price', 'financial', 'global', 'internet', 'may', 'ipo', 'fell', 'service', 'cents', 'tech', 'cash', '10', 'earlier', 'venture', 'much', 'amazon', 'could', 'software', 'chief', 'cloud', 'users', 'yahoo', 'months', 'biggest', 'stake', 'world', 'total', 'largest', 'expected', 'businesses', 'forecast', 'lyft', 'valued', 'offering', 'around', 'fund', 'executive']}\n"
     ]
    }
   ],
   "source": [
    "print(_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: FreqDist({'apple': 1253, 'company': 317, 'said': 310, 'iphone': 259, 'new': 215, 'percent': 213, 'sales': 201, 'pay': 197, 'china': 176, 'watch': 166, ...}), 1: FreqDist({'company': 1991, 'said': 1804, 'google': 1488, 'facebook': 1451, 'new': 1396, 'amazon': 1220, 'users': 1094, 'like': 1065, 'also': 993, 'people': 907, ...}), 2: FreqDist({'company': 2150, 'percent': 1851, 'said': 1363, 'revenue': 1115, 'investors': 756, 'shares': 743, 'quarter': 710, 'last': 684, 'new': 665, 'china': 665, ...})}\n"
     ]
    }
   ],
   "source": [
    "print(_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1, 2]\n",
      "1\n",
      "[0, 2]\n",
      "2\n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "_unique_keys={}\n",
    "for _cluster in range(3):   \n",
    "    print(_cluster)\n",
    "    _other_clusters=list(set(range(3))-set([_cluster]))\n",
    "    print(_other_clusters)\n",
    "    _keys_other_clusters=set(_keywords[_other_clusters[0]]).union(set(_keywords[_other_clusters[1]]))\n",
    "    _unique=set(_keywords[_cluster])-_keys_other_clusters\n",
    "    _unique_keys[_cluster]=nlargest(10, _unique, key=_counts[_cluster].get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['apple',\n",
       "  'iphone',\n",
       "  'watch',\n",
       "  'samsung',\n",
       "  'iphones',\n",
       "  'smartphone',\n",
       "  'store',\n",
       "  'music',\n",
       "  'phones',\n",
       "  'phone'],\n",
       " 1: ['facebook',\n",
       "  'twitter',\n",
       "  'ads',\n",
       "  'video',\n",
       "  'search',\n",
       "  'ad',\n",
       "  'mr.',\n",
       "  'get',\n",
       "  'way',\n",
       "  'social'],\n",
       " 2: ['investors',\n",
       "  'alibaba',\n",
       "  'share',\n",
       "  'stock',\n",
       "  'public',\n",
       "  'round',\n",
       "  'valuation',\n",
       "  'capital',\n",
       "  'raised',\n",
       "  'per']}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_unique_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "article = \"Facebook Inc. has been giving advertisers an inflated metric for the average time users spent watching a video, a measurement that may have helped boost marketer spending on one of Facebook’s most popular ad products. The company, owner of the world’s largest social network, only counts a video as viewed if it has been seen for more than 3 seconds. The metric it gave advertisers for their average video view time incorporated only the people who had watched the video long enough to count as a view in the first place, inflating the metric because it didn’t count anyone who didn’t watch, or watched for a shorter time. Facebook’s stock fell more than 1.5 percent in extended trading after the miscalculation was earlier reported in the Wall Street Journal. Facebook had disclosed the mistake in a posting on its advertiser help center web page several weeks ago. Big advertising buyers and marketers are upset about the inflated metric, and asked the company for more details, according to the report in the Journal, citing unidentified people familiar with the situation. The Menlo Park, California-based company has kept revenue surging in part because of enthusiasm for its video ads, which advertisers compare in performance to those on Twitter, YouTube and around the web.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "classifier.fit(X,km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_test = _vectorizer.transform([article.encode('ascii',errors='ignore')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x13036 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 85 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int32)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
