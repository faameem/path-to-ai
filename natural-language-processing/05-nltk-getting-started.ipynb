{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mary had a little lamb.', 'Her fleece was white as snow']\n",
      "\n",
      "['Mary', 'had', 'a', 'little', 'lamb', '.', 'Her', 'fleece', 'was', 'white', 'as', 'snow']\n"
     ]
    }
   ],
   "source": [
    "# tokenization\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# data\n",
    "text=\"Mary had a little lamb. Her fleece was white as snow\"\n",
    "\n",
    "# sentence tokenization\n",
    "sentence_list = sent_tokenize(text)\n",
    "print(sentence_list)\n",
    "\n",
    "# word tokenization\n",
    "word_list = word_tokenize(text)\n",
    "print('\\n{}'.format(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers']\n",
      "\n",
      "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n",
      "\n",
      "['his', 'by', 'wasn', 'and', 'needn', 'here', 'too', '#', 'to', '{', '%', 'y', 'not', '=', 'out', '`', 'hasn', 'he', 'off', '<']\n",
      "\n",
      "['Mary', 'little', 'lamb', 'Her', 'fleece', 'white', 'snow']\n"
     ]
    }
   ],
   "source": [
    "# stop words\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "english_stopwords = stopwords.words('english')\n",
    "print(english_stopwords[:20])\n",
    "\n",
    "punctuation_list = list(punctuation)\n",
    "print('\\n{}'.format(punctuation_list))\n",
    "\n",
    "custom_stopwords_distinct_list = list(set(english_stopwords + punctuation_list))\n",
    "print('\\n{}'.format(custom_stopwords_distinct_list[:20]))\n",
    "\n",
    "words_without_stopwords = [word for word in word_list if word not in custom_stopwords_distinct_list]\n",
    "print('\\n{}'.format(words_without_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('Her', 'fleece'), 1), (('Mary', 'little'), 1), (('fleece', 'white'), 1), (('lamb', 'Her'), 1), (('little', 'lamb'), 1), (('white', 'snow'), 1)]\n"
     ]
    }
   ],
   "source": [
    "# n-grams\n",
    "\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "\n",
    "bigram_finder = BigramCollocationFinder.from_words(words_without_stopwords)\n",
    "bigram_freq_dist = bigram_finder.ngram_fd.items()\n",
    "print(sorted(bigram_freq_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mary', 'clos', 'on', 'clos', 'night', 'when', 'she', 'was', 'in', 'the', 'mood', 'to', 'clos', '.']\n"
     ]
    }
   ],
   "source": [
    "# stemming\n",
    "\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "text2 = \"Mary closed on closing night when she was in the mood to close.\"\n",
    "\n",
    "stemmer = LancasterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in word_tokenize(text2)]\n",
    "print(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Mary', 'NNP'), ('closed', 'VBD'), ('on', 'IN'), ('closing', 'NN'), ('night', 'NN'), ('when', 'WRB'), ('she', 'PRP'), ('was', 'VBD'), ('in', 'IN'), ('the', 'DT'), ('mood', 'NN'), ('to', 'TO'), ('close', 'VB'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# POS - part of speech\n",
    "\n",
    "from nltk import pos_tag\n",
    "\n",
    "pos_tag_list = pos_tag(word_tokenize(text2))\n",
    "print(pos_tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('bass.n.01') the lowest part of the musical range\n",
      "Synset('bass.n.02') the lowest part in polyphonic music\n",
      "Synset('bass.n.03') an adult male singer with the lowest voice\n",
      "Synset('sea_bass.n.01') the lean flesh of a saltwater fish of the family Serranidae\n",
      "Synset('freshwater_bass.n.01') any of various North American freshwater fish with lean flesh (especially of the genus Micropterus)\n",
      "Synset('bass.n.06') the lowest adult male singing voice\n",
      "Synset('bass.n.07') the member with the lowest range of a family of musical instruments\n",
      "Synset('bass.n.08') nontechnical name for any of numerous edible marine and freshwater spiny-finned fishes\n",
      "Synset('bass.s.01') having or denoting a low vocal or instrumental range\n",
      "\n",
      " -- Synset('bass.n.07'), the member with the lowest range of a family of musical instruments\n",
      "\n",
      " -- Synset('sea_bass.n.01'), the lean flesh of a saltwater fish of the family Serranidae\n"
     ]
    }
   ],
   "source": [
    "# word sense disambiguation\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.wsd import lesk\n",
    "\n",
    "for synset in wordnet.synsets('bass'):\n",
    "    print(synset, synset.definition())\n",
    "\n",
    "sense1 = lesk(word_tokenize('Sing in a lower tone, along with the bass'),'bass')\n",
    "print('\\n -- {}, {}'.format(sense1, sense1.definition()))\n",
    "\n",
    "sense2 = lesk(word_tokenize('This sea bass was really hard to catch'),'bass')\n",
    "print('\\n -- {}, {}'.format(sense2, sense2.definition()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
